{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>text_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The crypto bull market remains in full throttl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mairs &amp;amp; Power, an investment management fi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Nvidia  (NVDA) - Get Report has been a bit of ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>You can only hate and love so much. The love f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Nvidia Corp.s stock and the broader chip secto...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  text_sent\n",
       "0           0  The crypto bull market remains in full throttl...          1\n",
       "1           1  Mairs &amp; Power, an investment management fi...          1\n",
       "2           2  Nvidia  (NVDA) - Get Report has been a bit of ...          1\n",
       "3           3  You can only hate and love so much. The love f...          1\n",
       "4           4  Nvidia Corp.s stock and the broader chip secto...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the dataset\n",
    "file_path = Path(\"Resources/Sentiments.csv\")\n",
    "Sentiment_df = pd.read_csv(file_path)\n",
    "Sentiment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the X and y vectors\n",
    "X = Sentiment_df[\"text\"].values\n",
    "y = Sentiment_df[\"text_sent\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras modules for data encoding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the Tokenizer and fit it with the X text data\n",
    "tokenizer = Tokenizer(lower=True)\n",
    "tokenizer.fit_on_texts(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word: 'the', token: 1\n",
      "word: 'chars', token: 2\n",
      "word: 'a', token: 3\n",
      "word: 'of', token: 4\n",
      "word: 'to', token: 5\n"
     ]
    }
   ],
   "source": [
    "# Print the first five elements of the encoded vocabulary\n",
    "for token in list(tokenizer.word_index)[:5]:\n",
    "    print(f\"word: '{token}', token: {tokenizer.word_index[token]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Text comment**\n",
      "{'The crypto bull market remains in full throttle. This has been good news for Nvidia (NVDA). The chip giant sells the GPUs used as crypto mining rigs, providing the company with another stream of reve… [+2648 chars]'}\n",
      "**Numerical sequence representation**\n",
      "[1, 553, 1270, 45, 695, 7, 921, 2187, 22, 18, 41, 267, 217, 11, 453, 240, 1, 342, 454, 2188, 1, 1271, 343, 15, 553, 1272, 2189, 2190, 1, 46, 20, 119, 2191, 4, 2192, 2193, 2]\n"
     ]
    }
   ],
   "source": [
    "# Transform the text data to numerical sequences\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "# Contrast a sample numerical sequence with its text version\n",
    "print(\"**Text comment**\")\n",
    "print({X[0]})\n",
    "print(\"**Numerical sequence representation**\")\n",
    "print(X_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding sequences\n",
    "X_pad = pad_sequences(X_seq, maxlen=140, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training, validation, and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, random_state=78)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and Train the LSTM RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Keras modules for model creation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model set-up\n",
    "vocabulary_size = len(tokenizer.word_counts.keys()) + 1\n",
    "max_words = 140\n",
    "embedding_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LSTM RNN model\n",
    "model = Sequential()\n",
    "\n",
    "# Layer 1\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "\n",
    "# Layer 2\n",
    "model.add(LSTM(units=280))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 140, 64)           333440    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 280)               386400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 281       \n",
      "=================================================================\n",
      "Total params: 720,121\n",
      "Trainable params: 720,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.6926\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6908\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6910\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6910\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6907\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6906\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6907\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6908\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6908\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1c8f1b7f388>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "batch_size = 1000\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=10,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louis\\Anaconda3\\envs\\deeplearnenv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# Make sentiment predictions\n",
    "predicted = model.predict_classes(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The table below compares the actual text (not the sequences) from the original dataframe to the predicted values\n",
    "# For that purpose we need to apply train_test_split with the same random state to the original X and save it as  X_test_original (we don't need the other values)\n",
    "_, X_test_original, _, _ = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Every week, Benzinga conducts a survey to coll...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(CNN) Photographer Faizan Ahmad had never even...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York, March 12, 2021 /PRNewswire/ -- Inves...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Palantir Technologies Inc (NYSE: PLTR) and Bla...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GettyAny interview conducted with Meghan Markl...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>Back in 1921, Dr. Charles P. Steinmetz, the pi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>The global chip shortage has caused havoc for ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>The Dow Jones Industrial Average rose but the ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Police say 21-year-old man charged with 10 mur...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>Arkema S.A., Akzo Nobel NV, PPG Industries, In...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text  Actual  Predicted\n",
       "0    Every week, Benzinga conducts a survey to coll...       1          1\n",
       "1    (CNN) Photographer Faizan Ahmad had never even...       1          1\n",
       "2    New York, March 12, 2021 /PRNewswire/ -- Inves...      -1          1\n",
       "3    Palantir Technologies Inc (NYSE: PLTR) and Bla...       1          1\n",
       "4    GettyAny interview conducted with Meghan Markl...       1          1\n",
       "..                                                 ...     ...        ...\n",
       "140  Back in 1921, Dr. Charles P. Steinmetz, the pi...       1          1\n",
       "141  The global chip shortage has caused havoc for ...      -1          1\n",
       "142  The Dow Jones Industrial Average rose but the ...      -1          1\n",
       "143  Police say 21-year-old man charged with 10 mur...      -1          1\n",
       "144  Arkema S.A., Akzo Nobel NV, PPG Industries, In...      -1          1\n",
       "\n",
       "[145 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame of Real and Predicted values\n",
    "sentiments = pd.DataFrame({\"Text\": X_test_original, \"Actual\": y_test, \"Predicted\": predicted.ravel()})\n",
    "sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN LSTM Accuracy 0.72\n"
     ]
    }
   ],
   "source": [
    "# Accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"RNN LSTM Accuracy %.2f\" % (accuracy_score(y_test, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix from the RNN LSTM Model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,  40],\n",
       "       [  0, 105]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import the confusion_matrix method from sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, predicted)\n",
    "print(\"Confusion Matrix from the RNN LSTM Model\")\n",
    "display(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for the RNN LSTM Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.00      0.00      0.00         0\n",
      "           1       1.00      0.72      0.84       145\n",
      "\n",
      "    accuracy                           0.72       145\n",
      "   macro avg       0.50      0.36      0.42       145\n",
      "weighted avg       1.00      0.72      0.84       145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\louis\\Anaconda3\\envs\\deeplearnenv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Import the classification_report method from sklearn\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Display classification report for the RNN LSTM Model\n",
    "print(\"Classification Report for the RNN LSTM Model\")\n",
    "print(classification_report(predicted, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deeplearnenv]",
   "language": "python",
   "name": "conda-env-deeplearnenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
